{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f8374c-9808-449e-b9b3-b372aec4a001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 5.4 – Feature Importance and SHAP Analysis\n",
    "### Geovanny Peña\n",
    "\n",
    "In this lab, I analyze how a Random Forest model makes predictions using global feature importance and SHAP explanations.  \n",
    "Although Logistic Regression was selected as the best tuned model in Assignment 5.3, Random Forest is used here because tree-based models provide clearer and more intuitive interpretability for feature importance and SHAP analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49417b43-f0e4-484e-8cc3-b873c4fbfe14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# Load feature pipeline\n",
    "pipeline = joblib.load(\"./etl_pipeline/stedi_feature_pipeline.pkl\")\n",
    "\n",
    "# Load transformed data\n",
    "X_train_transformed = joblib.load(\"./etl_pipeline/X_train_transformed.pkl\")\n",
    "X_test_transformed = joblib.load(\"./etl_pipeline/X_test_transformed.pkl\")\n",
    "\n",
    "# Helper function to ensure numeric arrays\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([x.toarray() if issparse(x) else np.array(x, dtype=float) for x in arr])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "\n",
    "# Load labels\n",
    "y_train = np.ravel(joblib.load(\"./etl_pipeline/y_train.pkl\"))\n",
    "y_test = np.ravel(joblib.load(\"./etl_pipeline/y_test.pkl\"))\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e023958-853b-4dc5-a3fd-7df860738699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The dataset shapes confirm that the transformed feature matrices and labels are aligned correctly and ready for model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3457a1-6f5f-4d85-9430-7af532b0b0fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest (use the same hyperparameters from 5.3)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model  # show summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44df5530-6be6-443d-bffe-99fbd6b9dc70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "importances = model.feature_importances_\n",
    "importance_order = np.argsort(importances)[::-1]\n",
    "\n",
    "try:\n",
    "    feature_names = pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "except:\n",
    "    feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Print top 10 features\n",
    "for idx in importance_order[:10]:\n",
    "    print(feature_names[idx], \":\", importances[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbd1fa0-f1ac-4cd0-9db6-e745e329d4b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Global Feature Importance Interpretation\n",
    "\n",
    "- The global feature importance results show a very strong dominance of the feature **num__distance_cm**, which accounts for approximately **92.7%** of the total importance in the Random Forest model. This indicates that the model relies primarily on the distance measurement to distinguish between *step* and *no_step* events.\n",
    "- This behavior is logically consistent with the STEDI dataset, as stepping movements are expected to produce systematic changes in distance that are not present during non-stepping states. Therefore, distance acts as a direct and highly informative signal for the classification task.\n",
    "- The remaining importance is distributed across categorical features such as **sensor_type** (accelerometer, gyroscope, ultrasonic sensor) and **device_id**. These features contribute marginally but likely help the model adjust predictions based on sensor characteristics or device-specific calibration differences.\n",
    "- While the dominance of a single feature may raise concerns about over-reliance, in this context it appears reasonable given the physical nature of the problem. As long as distance measurements are reliable, the model's importance pattern is interpretable and trustworthy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28792bd6-14ad-4548-90ca-0b3bedba32a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh([feature_names[i] for i in importance_order[:10]],\n",
    "         importances[importance_order[:10]])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top Global Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea41d081-3a6a-4f45-9c34-5dcda6b038d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This visualization highlights the features that contribute most to the Random Forest's decisions and will be useful for dashboard reporting in later assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "044d6684-b75d-4f9f-9ef2-d94e2a1a209c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Step 4 – Install and Import SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a6bde27-b72a-4ad4-9363-232d2e57ca6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe5b4f03-eb30-4364-b285-7080fdab4703",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b97b4543-0b14-46fc-b3cc-b30db6848e89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Create SHAP explainer for Random Forest\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Confirm shapes\n",
    "X_test.shape, shap_values[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d2dede-f4fb-4d73-a54e-e0599a2fe40d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 5 – SHAP Summary Plot (Global View)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65dfe925-e892-40c2-bebf-37d5cb8913ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values[..., 1],\n",
    "    X_test,\n",
    "    feature_names=feature_names,\n",
    "    rng=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebddb6d9-cb3e-4b09-9973-a3f88dcdd6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SHAP Summary Plot Observations\n",
    "\n",
    "- The SHAP summary plot confirms the findings from the global feature importance analysis. The feature **num__distance_cm** shows the largest spread of SHAP values, indicating that it has the strongest and most consistent influence on model predictions across the dataset.\n",
    "- Higher or lower values of distance significantly shift predictions toward either the *step* or *no_step* class, demonstrating that the model uses this feature as its primary decision driver.\n",
    "- Categorical features such as **sensor_type** and **device_id** appear lower in the ranking and exhibit much smaller SHAP magnitudes. Their influence is secondary and appears to fine-tune predictions rather than determine them outright.\n",
    "- Overall, the SHAP summary plot reinforces that the model behavior is coherent and largely driven by a physically meaningful variable, with no obvious signs of spurious or illogical feature influence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "524b46de-c281-40db-bc2d-136b5e2f7275",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 6 – SHAP Force Plot (Local Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0218562b-4ff0-469f-aabc-a62ec0e806e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "i = 0  # example index\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[...,1][i],\n",
    "    X_test[i],\n",
    "    feature_names=feature_names,\n",
    "    matplotlib=True  # <- static version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ec702b-cf1f-4640-857f-27d21e14314c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Local Prediction Explanation Using SHAP Force Plot\n",
    "\n",
    "- For the selected instance (index 0), the SHAP force plot shows that **num__distance_cm** is the primary feature influencing the prediction. In this case, its contribution is negative, pushing the model toward the *no_step* classification.\n",
    "- Several device-specific and sensor-related features contribute smaller positive or negative effects. These features slightly adjust the prediction but do not outweigh the dominant influence of distance.\n",
    "- The explanation is understandable and consistent with human reasoning: the observed distance value does not strongly resemble a stepping pattern, and therefore the model predicts *no_step*. A human analyst reviewing the same data would likely reach a similar conclusion based on this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8256dd3-19f2-4808-8a11-e3a7942ba779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# We choose the row we want to analyze.\n",
    "i = 0\n",
    "\n",
    "# We create a DataFrame with feature names and their SHAP contributions.\n",
    "shap_contributions = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"SHAP_value\": shap_values[...,1][i]  # valores para la clase 'step'\n",
    "})\n",
    "\n",
    "# We select the 10 features with the greatest absolute impact.\n",
    "top_shap = shap_contributions.reindex(shap_contributions.SHAP_value.abs().sort_values(ascending=False).index).head(10)\n",
    "\n",
    "# Show table\n",
    "display(top_shap)\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "colors = np.where(top_shap[\"SHAP_value\"] > 0, 'green', 'red')  # positive = green, negative = red\n",
    "plt.barh(top_shap[\"Feature\"], top_shap[\"SHAP_value\"], color=colors)\n",
    "plt.xlabel(\"SHAP Value (Impact on prediction)\")\n",
    "plt.title(f\"Top 10 Feature Impacts for prediction index {i}\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e760bab0-d9c3-4013-a3b2-e31fe059f7e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Additional Local SHAP Analysis\n",
    "\n",
    "- An inspection of the top SHAP contributions for this instance confirms that **num__distance_cm** has the largest absolute impact on the prediction. Its negative SHAP value indicates that the observed distance reduces the likelihood of a *step* classification.\n",
    "- All other features have SHAP values several orders of magnitude smaller, suggesting that their influence is minimal for this specific prediction. This further emphasizes the central role of distance in the model's decision-making process and highlights the relatively limited effect of sensor type and device identity at the local level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e487b4e8-84ab-4875-914b-c47ee04eca79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 7 – Reflection Questions (Model Behavior and Intuition)\n",
    "\n",
    "**Global Insight**\n",
    "\n",
    "Which features are the most important overall? Why do you think they matter for predicting step vs. no_step?\n",
    "\n",
    "- The most important feature by a very large margin is distance_cm, which alone accounts for more than 92% of the model's total feature importance.\n",
    "- This makes sense because the STEDI system detects steps based on changes in physical distance, so distance measurements are directly tied to step detection.\n",
    "- Sensor type features (accelerometer, gyroscope, ultrasonic sensor) appear next, but their importance is much smaller, suggesting they provide contextual support rather than being primary drivers.\n",
    "- Device-specific features (individual spotter IDs) have minor influence, indicating that the model relies more on movement patterns than on the specific device generating the data.\n",
    "\n",
    "**Local Insight**\n",
    "\n",
    "What did the SHAP force plot reveal about a single prediction? What features pushed the prediction up or down?\n",
    "\n",
    "- For the selected observation (index 0), distance_cm had the strongest negative SHAP value, pushing the prediction toward no_step.\n",
    "- This indicates that, for this specific row, the distance measurement was not consistent with a stepping motion.\n",
    "- Some sensor and device-related features (such as accelerometer and certain device IDs) had small positive SHAP values, slightly pushing the prediction toward step, but their influence was not strong enough to override the distance signal.\n",
    "- Overall, the prediction was dominated by physical distance rather than metadata or sensor type.\n",
    "\n",
    "**Human Intuition Check**\n",
    "\n",
    "Does the model's logic match what a human might expect from the STEDI data? Why or why not?\n",
    "\n",
    "- Yes, the model's behavior aligns well with human intuition. A person analyzing step data would naturally focus first on distance and movement patterns rather than on which device recorded the data.\n",
    "- The fact that distance overwhelmingly drives predictions suggests the model is learning meaningful physical signals rather than memorizing device identifiers.\n",
    "- The smaller contributions from sensor type also make sense, as different sensors capture motion differently but should not dominate the decision on their own.\n",
    "\n",
    "**Dashboard Preparation**\n",
    "\n",
    "Which visualizations from this lab do you plan to include in your Week 6 dashboard?\n",
    "\n",
    "- I plan to include the Global Feature Importance bar chart to clearly show which features the model relies on overall.\n",
    "- The SHAP summary plot will be included to illustrate both the direction and magnitude of feature effects across all predictions.\n",
    "- I will also include one local explanation (either the SHAP force plot or the SHAP contribution bar chart) to demonstrate how the model makes a decision for an individual data point.\n",
    "- Together, these visuals provide both transparency and interpretability for technical and non-technical audiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7f3fb1c-5979-4f26-99f3-130d2b3b7726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predicciones en el set de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Reporte de métricas\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1394909-d325-4da6-8034-76f6b8239c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcular confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Crear heatmap manual con matplotlib\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xticks([0, 1], [\"no_step\", \"step\"])\n",
    "plt.yticks([0, 1], [\"no_step\", \"step\"])\n",
    "\n",
    "# Mostrar valores dentro de la matriz\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b674a94e-989c-4561-b6c2-4dc51d6978a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Probabilidades para la clase positiva (step)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "assignment_5_4",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
