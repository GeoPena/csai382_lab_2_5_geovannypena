{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6f9545-7128-4836-9693-17f6278ffc42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 4.4 – Trained ML Models: Compare Models\n",
    "### Geovanny Peña Rueda\n",
    "In this assignment, I train baseline machine learning models using the transformed STEDI dataset.\n",
    "I compare Logistic Regression and Random Forest models and evaluate their baseline accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cd185b1-40a7-4576-928a-724a817d94e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Import Libraries and Load Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e187f37-9cf1-4ea4-99ef-e11c5f90d7cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "pipeline = joblib.load(\"./etl_pipeline/stedi_feature_pipeline.pkl\")\n",
    "\n",
    "X_train_transformed = joblib.load(\"./etl_pipeline/X_train_transformed.pkl\")\n",
    "X_test_transformed = joblib.load(\"./etl_pipeline/X_test_transformed.pkl\")\n",
    "\n",
    "y_train = joblib.load(\"./etl_pipeline/y_train.pkl\")\n",
    "y_test = joblib.load(\"./etl_pipeline/y_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "278441c4-2052-4973-ae77-512a24a354ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensures that input arrays (possibly object-dtype, sparse, or 0-d)\n",
    "    are converted to a 2-D float matrix.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1952c949-34eb-4538-840b-1fc1f05dca92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2fd9aad-96b7-439e-90e7-a750b0cc3698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Train Logistic Regression (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98c338b-0d53-403a-8804-219ec2ee7e0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a0e6a5b-f9a4-4a12-82e8-716749e00dce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Train Random Forest (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff84ef6-5f09-4f30-8878-8e248c4fc591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4440aca5-5e91-4059-87bd-143721179653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Compare Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "252caccf-5054-4559-bbe0-8fae3d2a0eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8142fdcf-0d50-4a1d-a78b-8fb246dc358e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Baseline Model Analysis\n",
    "\n",
    "**Which baseline model performed better?**  \n",
    "The Logistic Regression model performed slightly better than the Random Forest model based on accuracy results.\n",
    "\n",
    "**Which model seems more stable for noisy sensor data?**  \n",
    "The Random Forest model is generally more stable for noisy sensor data because it combines the results of many decision trees, which helps reduce the impact of outliers and noise.\n",
    "\n",
    "**What questions do you have about why the numbers differ?**  \n",
    "One question is whether the strong feature engineering and scaling allowed Logistic Regression to perform as well as, or better than, a more complex model like Random Forest. Another question is how the results might change with different hyperparameters.\n",
    "\n",
    "**Why is it important to test your model before using it in real life?**  \n",
    "Testing is important because models can make mistakes, and using an untested model could lead to incorrect decisions or harmful outcomes.\n",
    "\n",
    "**If a model is wrong, who could be affected?**  \n",
    "If a model is wrong, users who rely on its predictions could be affected, such as customers, patients, or organizations that use the model for decision-making.\n",
    "\n",
    "**Why does fairness matter in both data science and discipleship?**  \n",
    "Fairness matters in data science because models should treat all data and people responsibly and without bias. In discipleship, fairness and consistency reflect moral accountability and the responsibility to act with integrity and care toward others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2967efe6-8e2d-4c31-b3a6-e056279e0db5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da8cb315-496f-4f0b-96ee-f732ec4a19d0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save trained models (fixed for serverless)"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "# Create a unique folder name (prevents overwriting files)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_dir = f\"stedi_models/{run_id}\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "# Save trained models\n",
    "joblib.dump(log_reg, f\"{base_dir}/log_reg.joblib\")\n",
    "joblib.dump(rf, f\"{base_dir}/random_forest.joblib\")\n",
    "# Save accuracy information (metadata)\n",
    "metadata = {\n",
    "    \"run_id\": run_id,\n",
    "    \"logistic_regression_accuracy\": float(log_reg_score),\n",
    "    \"random_forest_accuracy\": float(rf_score),\n",
    "}\n",
    "joblib.dump(metadata, f\"{base_dir}/metadata.joblib\")\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a0bb47-f048-4c27-96f4-91ef131db0bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "zip_path = f\"stedi_models_{run_id}.zip\"\n",
    "shutil.make_archive(f\"stedi_models_{run_id}\", \"zip\", base_dir)\n",
    "\n",
    "zip_path\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "assignment_4_4",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
