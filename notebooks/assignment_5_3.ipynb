{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3625e6a-5e71-4ee9-81dd-a5c83f8386a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 5.3 - Trained ML Models: Hyperparameter Tuning\n",
    "### Geovanny Peña\n",
    "In this assignment, I improve the baseline machine-learning models by tuning their hyperparameters and selecting the strongest model based on validation performance. I tune both Logistic Regression and Random Forest models using GridSearchCV, compare their results, and save the best-performing model for future analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "456caa47-9758-412c-a91b-7316356b266b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Import Libraries and Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c732404-0ca1-436e-a642-2ec602f8461f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a573b2b-f5b9-486b-af48-dc9804d56457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline = joblib.load(\"./etl_pipeline/stedi_feature_pipeline.pkl\")\n",
    "\n",
    "X_train_transformed = joblib.load(\"./etl_pipeline/X_train_transformed.pkl\")\n",
    "X_test_transformed = joblib.load(\"./etl_pipeline/X_test_transformed.pkl\")\n",
    "\n",
    "y_train = joblib.load(\"./etl_pipeline/y_train.pkl\")\n",
    "y_test = joblib.load(\"./etl_pipeline/y_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a491493-b4a3-4ac3-adc7-e97121846417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensures that input arrays (possibly object-dtype, sparse, or 0-d)\n",
    "    are converted to a 2-D float matrix.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ac9575-80c4-4d5f-bf7c-393fc9dca66d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f015436f-e960-4113-9b82-d9272d098c5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Hyperparameter Tuning - Logistic Regression\n",
    "I used GridSearchCV to test different regularization strengths and solvers for Logistic Regression. The goal was to identify the combination of hyperparameters that provides the best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ec3937-daff-433a-ad66-af0144a95478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a98c4e1-60c4-401e-b9c1-7dbc4f9fc458",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_reg_params = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e26cb20b-85a5-4a7c-a7d5-a032cfef9766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_reg_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=300),\n",
    "    log_reg_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "\n",
    "log_reg_best_params = log_reg_grid.best_params_\n",
    "log_reg_best_score = log_reg_grid.best_score_\n",
    "\n",
    "log_reg_best_params, log_reg_best_score\n",
    "\n",
    "print(\"Logistic Regression Best Params:\", log_reg_grid.best_params_)\n",
    "print(\"Logistic Regression Best CV Score:\", log_reg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfde92e0-a122-4f75-9fcd-59a689ff3048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Hyperparameter Tuning – Random Forest\n",
    "I used GridSearchCV to tune key Random Forest hyperparameters, including the number of trees, tree depth, and minimum sample requirements. This helps balance model accuracy and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d438d04-a597-4f73-a361-4160c63aa592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbb252b-bc18-44c7-8600-d1b1ef4c33e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "120aa62e-c77d-4939-9fa4-df5423916c8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    rf_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rf_best_params = rf_grid.best_params_\n",
    "rf_best_score = rf_grid.best_score_\n",
    "\n",
    "rf_best_params, rf_best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46398287-3272-4058-97b4-f8041af738c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Compare Tuned Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac52ba2-0787-4451-a166-ade4502f2141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression (tuned)\": log_reg_best_score,\n",
    "    \"Random Forest (tuned)\": rf_best_score\n",
    "}\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "285a2083-5cca-4fbc-bcf2-8aae4a2f63ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Choose the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b786f808-bd50-4c1a-9434-7d9a64ac4e9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if rf_best_score > log_reg_best_score:\n",
    "    best_model = rf_grid.best_estimator_\n",
    "    best_model_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = log_reg_grid.best_estimator_\n",
    "    best_model_name = \"Logistic Regression\"\n",
    "\n",
    "best_model_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "055e43b7-9ed8-4e99-95b5-5d188bca0b50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e33b0265-32c2-4cf0-9b70-7f2048202692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model = log_reg_grid.best_estimator_\n",
    "joblib.dump(best_model, \"stedi_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91882b1b-7839-4d56-a13a-172cf905d36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c8b8e1-a158-4081-9a63-162e268d145e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Evaluation Report and Ethics Reflection\n",
    "\n",
    "**Which model performed best?**\n",
    "The tuned Logistic Regression model was selected as the best model.\n",
    "\n",
    "**How do you know? (accuracy, precision, recall?)** \n",
    "Both tuned models achieved the same cross-validation accuracy (about 95.1%), but Logistic Regression was chosen because it is simpler and more interpretable. Accuracy was the main metric used for comparison in this assignment.\n",
    "\n",
    "**What hyperparameters improved performance?** \n",
    "For Logistic Regression, a smaller C value (0.01) improved performance by increasing regularization and reducing overfitting. For Random Forest, limiting the max_depth to 5 and using fewer trees helped control model complexity.\n",
    "\n",
    "**Any surprising results?** \n",
    "It was surprising that both tuned models reached almost the exact same accuracy, even though Random Forest is usually more powerful. This suggests that the features in the dataset are well structured and mostly linearly separable.\n",
    "\n",
    "**What would you test next if you had more time?** \n",
    "I would test additional evaluation metrics such as precision and recall, try more Random Forest parameters, or experiment with other models like Gradient Boosting or XGBoost. I would also explore adding more sensor features or collecting more data.\n",
    "\n",
    "**How could hyperparameter tuning accidentally make a model unfair or biased?** \n",
    "Hyperparameter tuning can unintentionally favor patterns that work well for the majority group but perform poorly for smaller or underrepresented groups. If the tuning process only focuses on overall accuracy, it may hide unfair behavior in specific populations.\n",
    "\n",
    "**Why is transparency important, and how does the gospel teach honest evaluation?** \n",
    "Transparency allows others to understand how decisions were made and to identify potential bias or errors. The gospel teaches principles of integrity, reminding us to evaluate our work truthfully and responsibly, especially when our decisions can affect others."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "assignment_5_3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
